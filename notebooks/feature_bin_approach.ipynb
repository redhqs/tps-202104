{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12f299a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import make_column_transformer, ColumnTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import CategoricalNB, BernoulliNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score, log_loss, make_scorer\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c65803",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"paper\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a001461a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/raw/train.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e17bfcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\"../data/raw/test.csv\")\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e619f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df[['Survived']]\n",
    "features = df[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked', 'Cabin', 'Ticket']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab17ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "na_fill = {'Embarked': 'X', 'Cabin': 'X', 'Ticket': 'X'}\n",
    "features.fillna(value=na_fill, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57da9c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_embarked = pd.get_dummies(features['Embarked'], prefix='Embarked')\n",
    "\n",
    "features['Ticket'] = features['Ticket'].fillna('X').map(lambda x:str(x).split()[0] if len(str(x).split()) > 1 else 'X') \\\n",
    "                               .str.upper() \\\n",
    "                               .replace(\"[^a-zA-Z0-9]*\", \"\", regex=True)\n",
    "df_ticket = pd.get_dummies(features['Ticket'], prefix='Ticket')\n",
    "\n",
    "features['Cabin'] = features['Cabin'].map(lambda x: x[0].strip())\n",
    "df_cabin = pd.get_dummies(features['Cabin'], prefix='Cabin')\n",
    "\n",
    "features.loc[(features['Fare'].isna()) & (features['Pclass']==1) & (features['Sex']=='female'), 'Fare']=85.40\n",
    "features.loc[(features['Fare'].isna()) & (features['Pclass']==2) & (features['Sex']=='female'), 'Fare']=24.75\n",
    "features.loc[(features['Fare'].isna()) & (features['Pclass']==3) & (features['Sex']=='female'), 'Fare']=12.54\n",
    "\n",
    "age_map = features[['Age', 'Sex']].dropna().groupby(['Sex']).median().to_dict()\n",
    "features['Age'] = features['Age'].fillna(features['Sex'].map(age_map['Age']))\n",
    "bins1 = ['Y1', 'Y2', 'Y3', 'Y4', 'M1', 'M2', 'E']\n",
    "features['Age_Bin'] = pd.cut(x=features['Age'],\n",
    "                            bins=[0, 5 , 10, 15, 20, 30, 50,1000],\n",
    "                            labels=bins1,right=False)\n",
    "features['Age_Bin'] = features['Age_Bin'].astype('str')\n",
    "features['Age_Bin'] = features['Age_Bin']+features['Sex']\n",
    "\n",
    "df_age_bin = pd.get_dummies(features['Age_Bin'], prefix='Age_bin')\n",
    "\n",
    "bins2 = ['L1', 'L2', 'L3', 'L4']\n",
    "features['Fare_Bin'] = pd.cut(x=features['Fare'],\n",
    "                            bins=[0,11, 30 , 60, 10000],\n",
    "                            labels=bins2,right=False)\n",
    "features['Fare_Bin'] = features['Fare_Bin'].astype('str')\n",
    "df_fare_bin = pd.get_dummies(features['Fare_Bin'], prefix='Fare_bin')\n",
    "\n",
    "features['Sex'] = features['Sex'].apply(lambda x: 1 if x=='female' else 0).astype('uint8')\n",
    "\n",
    "df_pclass = pd.get_dummies(features['Pclass'], prefix='class')\n",
    "\n",
    "features['FamilySize'] = features['Parch'] + features['SibSp'] + 1\n",
    "features['Singleton'] = features['FamilySize'].map(lambda s: 1 if s == 1 else 0).astype('uint8')\n",
    "features['SmallFamily'] = features['FamilySize'].map(lambda s: 1 if 2 <= s <= 4 else 0).astype('uint8')\n",
    "features['LargeFamily'] = features['FamilySize'].map(lambda s: 1 if 5 <= s else 0).astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d59d675",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.concat([df_embarked, df_ticket, df_cabin, df_age_bin, df_fare_bin, df_pclass,\n",
    "                  features['Singleton'], features['SmallFamily'], features['LargeFamily'],\n",
    "                  features['Sex']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac55fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85508aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# naive bayes\n",
    "no_param = {'fit_prior':[True, False], 'alpha':[0.1, 0.3, 0.6, 0.9]}\n",
    "\n",
    "# gradient boosting classifier\n",
    "mini_param = {\n",
    "    \"loss\":[\"deviance\"], \n",
    "    \"learning_rate\": [0.15, 0.3],\n",
    "    \"n_estimators\": [200, 400],\n",
    "    \"subsample\": [0.7, 0.9],\n",
    "    \"criterion\": [\"mse\"],\n",
    "    \"max_depth\": [15, 30],\n",
    "    \"max_features\": [\"sqrt\", None],\n",
    "    \"random_state\": [42],\n",
    "    \"validation_fraction\": [0.1],\n",
    "    \"n_iter_no_change\": [15]}\n",
    "\n",
    "# adaboost classifier\n",
    "ada_param = {\n",
    "    \"n_estimators\": [100, 200, 500],\n",
    "    \"random_state\": [42],\n",
    "    \"learning_rate\": [0.1, 0.3, 0.9],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62e5b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_nb = GridSearchCV(clf, param_grid=mini_param, refit=True, scoring='accuracy', cv=3, n_jobs=1, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f39d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_nb.fit(train, np.ravel(target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca4261c",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_nb.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf9cbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc = grid_nb.predict(train)\n",
    "print(classification_report(target, train_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e9b1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(target, train_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ac3dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = test_df[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked', 'Cabin', 'Ticket']]\n",
    "test_features.fillna(value=na_fill, inplace=True)\n",
    "test_df_embarked = pd.get_dummies(test_features['Embarked'], prefix='Embarked')\n",
    "\n",
    "test_features['Ticket'] = test_features['Ticket'].fillna('X').map(lambda x:str(x).split()[0] if len(str(x).split()) > 1 else 'X') \\\n",
    "                               .str.upper() \\\n",
    "                               .replace(\"[^a-zA-Z0-9]*\", \"\", regex=True)\n",
    "test_df_ticket = pd.get_dummies(test_features['Ticket'], prefix='Ticket')\n",
    "\n",
    "test_features['Cabin'] = test_features['Cabin'].map(lambda x: x[0].strip())\n",
    "test_df_cabin = pd.get_dummies(test_features['Cabin'], prefix='Cabin')\n",
    "\n",
    "test_features.loc[(test_features['Fare'].isna()) & (test_features['Pclass']==1) & (test_features['Sex']=='female'), 'Fare']=85.40\n",
    "test_features.loc[(test_features['Fare'].isna()) & (test_features['Pclass']==2) & (test_features['Sex']=='female'), 'Fare']=24.75\n",
    "test_features.loc[(test_features['Fare'].isna()) & (test_features['Pclass']==3) & (test_features['Sex']=='female'), 'Fare']=12.54\n",
    "\n",
    "test_features['Age'] = test_features['Age'].fillna(test_features['Sex'].map(age_map['Age']))\n",
    "test_features['Age_Bin'] = pd.cut(x=test_features['Age'],\n",
    "                            bins=[0, 5 , 10, 15, 20, 30, 50,1000],\n",
    "                            labels=bins1,right=False)\n",
    "test_features['Age_Bin'] = test_features['Age_Bin'].astype('str')\n",
    "test_features['Age_Bin'] = test_features['Age_Bin']+test_features['Sex']\n",
    "\n",
    "test_df_age_bin = pd.get_dummies(test_features['Age_Bin'], prefix='Age_bin')\n",
    "\n",
    "test_features['Fare_Bin'] = pd.cut(x=test_features['Fare'],\n",
    "                            bins=[0,11, 30 , 60, 10000],\n",
    "                            labels=bins2,right=False)\n",
    "test_features['Fare_Bin'] = test_features['Fare_Bin'].astype('str')\n",
    "test_df_fare_bin = pd.get_dummies(test_features['Fare_Bin'], prefix='Fare_bin')\n",
    "\n",
    "test_features['Sex'] = test_features['Sex'].apply(lambda x: 1 if x=='female' else 0).astype('uint8')\n",
    "\n",
    "test_df_pclass = pd.get_dummies(test_features['Pclass'], prefix='class')\n",
    "\n",
    "test_features['FamilySize'] = test_features['Parch'] + features['SibSp'] + 1\n",
    "test_features['Singleton'] = test_features['FamilySize'].map(lambda s: 1 if s == 1 else 0).astype('uint8')\n",
    "test_features['SmallFamily'] = test_features['FamilySize'].map(lambda s: 1 if 2 <= s <= 4 else 0).astype('uint8')\n",
    "test_features['LargeFamily'] = test_features['FamilySize'].map(lambda s: 1 if 5 <= s else 0).astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648b0a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.concat([test_df_embarked, test_df_ticket, test_df_cabin, test_df_age_bin, test_df_fare_bin, test_df_pclass,\n",
    "                  test_features['Singleton'], test_features['SmallFamily'], test_features['LargeFamily'],\n",
    "                  test_features['Sex']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6292ed84",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = grid_nb.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adae417d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9d6e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_out = \"../data/inference/cv_ab.csv\"\n",
    "test_df['Survived'] = test_preds.tolist()\n",
    "test_submission = test_df[['PassengerId', 'Survived']]\n",
    "test_submission.to_csv(file_out, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d923b1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ab = \"../data/inference/cv_ab.csv\"\n",
    "xgb = \"../data/inference/cv_acc_xgb.csv\"\n",
    "gbc = \"../data/inference/cv_f1_gb.csv\"\n",
    "gbc_cat = \"../data/inference/cv_gbc.csv\"\n",
    "nb = \"../data/inference/cv_nb.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c34353",
   "metadata": {},
   "outputs": [],
   "source": [
    "ab_df = pd.read_csv(ab).rename(columns={'PassengerId': 'id1', 'Survived': 'ab'})\n",
    "xgb_df = pd.read_csv(xgb).rename(columns={'PassengerId': 'id2', 'Survived': 'xgb'})\n",
    "gbc_df = pd.read_csv(gbc).rename(columns={'PassengerId': 'id3', 'Survived': 'gbc'})\n",
    "gbc_cat_df = pd.read_csv(gbc_cat).rename(columns={'PassengerId': 'id4', 'Survived': 'gbc_cat'})\n",
    "nb_df = pd.read_csv(nb).rename(columns={'Survived': 'nb'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b0f6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ens = pd.concat([ab_df, xgb_df, gbc_df, gbc_cat_df, nb_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95e4741",
   "metadata": {},
   "outputs": [],
   "source": [
    "ens.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f51593f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ens['Survived'] = ens[['ab', 'xgb', 'gbc', 'gbc_cat', 'nb']].median(axis=1).astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ae7f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ens[['PassengerId', 'Survived']].to_csv(\"../data/inference/ensemble.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
