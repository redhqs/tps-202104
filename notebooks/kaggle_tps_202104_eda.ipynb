{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "serious-dallas",
   "metadata": {},
   "source": [
    "### EDA of Apr 2021 kaggle TPS\n",
    "\n",
    "This notebook is used to do initial exploration of the training data, get an understanding of the distribution and completeness of each column and relationship with the target. The aim is to build a broad understanding and make some baseline predictions.\n",
    "\n",
    "Synthanic [Data Dictionary](https://www.kaggle.com/c/tabular-playground-series-apr-2021/data?select=train.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "raised-specialist",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports for EDA\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.graphics.mosaicplot import mosaic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "personal-algorithm",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports for inference\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2410b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa19d108",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"paper\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "narrow-davis",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/raw/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floating-bacteria",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "metric-range",
   "metadata": {},
   "source": [
    "We can get some idea of what to expect from the first few rows - next to look at the distribution of each more closely, and think about how to handle missing data and how to encode sex, class, port of embarkation etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opposed-hanging",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1180ed4",
   "metadata": {},
   "source": [
    "Noting null values in Age, Ticket, Fare, Cabin and Embarked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organic-applicant",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabulous-raising",
   "metadata": {},
   "source": [
    "So with a 43% survival rate, hopefully we can do better than predicting everyone as lost at 57%. Noticing a lot of missing ages, not so many missing fares. \n",
    "\n",
    "For the purposes of this challend I'm assuming the passenger IDs are all ok - on to survival, and lots of plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "checked-martin",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data=df, x=\"Survived\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bottom-break",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data=df, x=\"Pclass\", hue=\"Survived\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e6df58",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data=df, x=\"Sex\", hue=\"Survived\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "received-dealing",
   "metadata": {},
   "source": [
    "No missing values here - but note significant differences in outcomes between male and female."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd2b638",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['Sex', 'Survived'])['Survived'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30621c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mosaic(df, ['Pclass', 'Sex', 'Survived'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accepted-heater",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(data=df, x=\"Age\", hue=\"Survived\", kind=\"kde\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outer-workshop",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.countplot(data=df, x=\"SibSp\", hue=\"Survived\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498cfa1a",
   "metadata": {},
   "source": [
    "The SibSp chart is dominated by the number of passengers with 0 or 1 - let's zoom in on 2+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc9ea78",
   "metadata": {},
   "outputs": [],
   "source": [
    "dplot = sns.countplot(data=df, x=\"SibSp\", hue=\"Survived\")\n",
    "dplot.set(xlim=(1.5, 6.5))\n",
    "dplot.set(ylim=(0.0, 2100.0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bibliographic-region",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.countplot(data=df, x=\"Parch\", hue=\"Survived\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c277846",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dplot = sns.countplot(data=df, x=\"Parch\", hue=\"Survived\")\n",
    "dplot.set(xlim=(0.5, 7.5))\n",
    "dplot.set(ylim=(0, 8000))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea97f3bd",
   "metadata": {},
   "source": [
    "Values (and the lack of) from 5+ in SibSp and 4+ in Parch may lead to overfitting in the unseen data - binning these into broader categories could be more robust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adverse-effect",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of unique tickets: {}\".format(df['Ticket'].nunique()))\n",
    "print(\"Number of null tickets: {}\".format(df['Ticket'].isnull().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nutritional-challenge",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.displot(data=df, x=\"Fare\", hue=\"Survived\", kind=\"kde\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secure-pledge",
   "metadata": {},
   "source": [
    "Those paying < 100 did not do so well. Let's take a closer look at passengers who paid more:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ignored-smart",
   "metadata": {},
   "outputs": [],
   "source": [
    "dplot = sns.displot(data=df, x=\"Fare\", hue=\"Survived\", kind=\"kde\")\n",
    "dplot.set(xlim=(100, 800))\n",
    "dplot.set(ylim=(0, 0.001))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southwest-northeast",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of passengers missing embarkation port: {}\".format(df['Embarked'].isnull().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a498e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_fill = {'Embarked': 'X'}\n",
    "df.fillna(value=emb_fill, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ranking-greeting",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.groupby(['Embarked', 'Survived'])['Survived'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rapid-ancient",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(data=df, x=\"Embarked\", hue=\"Survived\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29894c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Cabin'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da869df",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of unique cabin IDs: {}\".format(df['Cabin'].nunique()))\n",
    "print(\"Number of null cabin IDs: {}\".format(df['Cabin'].isnull().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2cf8e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['CabinArea'] = df['Cabin'].fillna('X').map(lambda x: x[0].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990429e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.countplot(data=df, x=\"CabinArea\", hue=\"Survived\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be80342",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Ticket'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f00516",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Number of unique ticket IDs: {}\".format(df['Ticket'].nunique()))\n",
    "print(\"Number of null ticket IDs: {}\".format(df['Ticket'].isnull().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663b3820",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['TicketStub'] = df['Ticket'].fillna('X').map(lambda x:str(x).split()[0] if len(str(x).split()) > 1 else 'X').lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac63b033",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['TicketStub'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b40285",
   "metadata": {},
   "source": [
    "Clearly some cleaning to be done here - for example 'SC/PARIS', 'S.C./PARIS', 'SC/Paris' look similar. What sort of frequencies are we looking at here, is this worth pursuing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e01b67",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.groupby(['TicketStub'], sort=False, dropna=True)['Survived'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f72b33a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.groupby(['TicketStub'], sort=False, dropna=True)['Survived'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abandoned-batman",
   "metadata": {},
   "source": [
    "So, maybe? There is work to be done to work out the best way to impute missing data around Age, SibSp, Parch, Ticket, Cabin, and Embarked, but first I want to compare a quick mvp to a dummy benchmark to set a baseline. For this the categorical columns will need to be encoded, nulls filled with temporary junk, after breaking out to a train/test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "empty-flooring",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df[['Survived']]\n",
    "features = df[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked', 'CabinArea', 'TicketStub']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "south-kingdom",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "maritime-drove",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = ['Pclass', 'Sex', 'Embarked', 'CabinArea', 'TicketStub']\n",
    "numeric = ['Age', 'SibSp', 'Parch', 'Fare']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sustainable-greek",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[numeric].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95fd277",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.displot(data=X_train, x='Fare', kind='ecdf')\n",
    "sns.displot(data=X_train, x='Fare', kind='kde')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stable-dietary",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fare_map = X_train[['Fare', 'Pclass']].dropna().groupby('Pclass').median().to_dict()\n",
    "X_train['Fare'] = X_train['Fare'].fillna(X_train['Pclass'].map(fare_map['Fare']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f9ca45",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fare_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6bf799",
   "metadata": {},
   "source": [
    "Other ideas on handling missing data:\n",
    "- X_train['Age'] = X_train.groupby(['Sex','Pclass'], sort=False)['Age'].apply(lambda x: x.fillna(x.median()))\n",
    "- X_train['Fare'] = X_train.groupby(['Pclass'], sort=False)['Fare'].apply(lambda x: x.fillna(x.median()))\n",
    "\n",
    "Turned out to be difficult to apply to the unseen data, the mapping works much better and is more explainable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0024b566",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(data=X_train, x='Age', kind='kde')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noticed-population",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# can't quite get this to work - could be worth exploring later\n",
    "draft_age_map = X_train[['Age', 'Sex', 'Pclass']].dropna().groupby(['Sex', 'Pclass']).median().to_dict()\n",
    "draft_age_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4269dc90",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_map = X_train[['Age', 'Sex']].dropna().groupby(['Sex']).median().to_dict()\n",
    "X_train['Age'] = X_train['Age'].fillna(X_train['Sex'].map(age_map['Age']))\n",
    "age_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc66a712",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(data=X_train, x='Age', kind='kde')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572deff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wooden-cameroon",
   "metadata": {},
   "source": [
    "With nulls filled and a train/test split specified, numeric columns are scaled and categorical columns are encoded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5a0756",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = ['Pclass', 'Sex', 'Embarked', 'CabinArea', 'TicketStub']\n",
    "numeric = ['Age', 'SibSp', 'Parch', 'Fare']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "relevant-aerospace",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = make_column_transformer(\n",
    "    (StandardScaler(), numeric),\n",
    "    (OneHotEncoder(drop='if_binary'), categorical), \n",
    "    remainder='drop')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ba7255",
   "metadata": {},
   "source": [
    "Initial estimator is logistic regression as a baseline for a binary classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61dc1a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_pipeline(\n",
    "    preprocessor,\n",
    "    LogisticRegression(penalty='elasticnet', solver='saga', l1_ratio=0.5))\n",
    "\n",
    "_ = model.fit(X_train, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "floral-catering",
   "metadata": {},
   "source": [
    "To set a floor for model performance, let's see a classification report if the ship is predicted as going down with no survivors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collect-savings",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_train)\n",
    "y_dummy = np.full(shape=len(y_pred), fill_value=0)\n",
    "print(classification_report(y_train, y_dummy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "innovative-munich",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accredited-progressive",
   "metadata": {},
   "source": [
    "Performance on training data is ok at 77% overall accuracy; better than guessing that no one makes it at least, at 57% accuracy. Compare to the held out test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95fca6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "explicit-chance",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# using age and fare maps from X_train, no peeking\n",
    "X_test['Fare'] = X_test['Fare'].fillna(X_test['Pclass'].map(fare_map['Fare']))\n",
    "X_test['Age'] = X_test['Age'].fillna(X_test['Sex'].map(age_map['Age']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c2c081",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_unseen = model.predict(X_test)\n",
    "print(classification_report(y_test, y_unseen))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "social-eight",
   "metadata": {},
   "source": [
    "To finish with the same steps are carried out on the competition test set and submitted. With more time you could do EDA on the test set to look for drift across each category, but for right now I'm interested in how this model performs without any additional intervention."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "combined-sleep",
   "metadata": {},
   "source": [
    "This initial submission achieved a leaderboard score of 0.77000. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sustained-opinion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# there needs to be a proper CV grid search eventually - submitting this as is to kaggle yielded leaderboard score of 0.78642\n",
    "model_gb = make_pipeline(\n",
    "    preprocessor,\n",
    "    GradientBoostingClassifier())\n",
    "\n",
    "_ = model_gb.fit(X_train, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "behind-attitude",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_gb = model_gb.predict(X_train)\n",
    "print(classification_report(y_train, y_pred_gb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equivalent-hanging",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_unseen_gb = model_gb.predict(X_test)\n",
    "print(classification_report(y_test, y_unseen_gb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sticky-cleaning",
   "metadata": {},
   "source": [
    "The ensemble method achieved a leaderboard score of 0.78642 out of the box. Let's see what a moderate parameter search yields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dff07b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_param = {'random_state': [42],\n",
    "            'solver': ['saga'],\n",
    "            'penalty': ['elasticnet'],\n",
    "            'l1_ratio': [0.5]} \n",
    "\n",
    "mini_param = {\n",
    "    \"loss\":[\"deviance\"], \n",
    "    \"learning_rate\": [0.2],\n",
    "    \"n_estimators\": [250],\n",
    "    \"subsample\": [0.8],\n",
    "    \"criterion\": [\"mse\"],\n",
    "    \"max_depth\": [15],\n",
    "    \"max_features\": [\"sqrt\"],\n",
    "    \"random_state\": [42],\n",
    "    \"validation_fraction\": [0.1],\n",
    "    \"n_iter_no_change\": [10]}\n",
    "\n",
    "param_grid = {\n",
    "    \"loss\":[\"deviance\", \"exponential\"], \n",
    "    \"learning_rate\": [0.01, 0.025, 0.05, 0.075, 0.1, 0.15, 0.2],\n",
    "    \"n_estimators\":[100, 250, 500],\n",
    "    \"subsample\":[0.5, 0.8, 0.9, 1.0],\n",
    "    \"criterion\": [\"friedman_mse\",  \"mse\"],\n",
    "    \"max_depth\":[6, 9, 15],\n",
    "    \"max_features\":[\"log2\",\"sqrt\"],\n",
    "    \"random_state\":[42],\n",
    "    \"validation_fraction\":[0.1],\n",
    "    \"n_iter_no_change\":[5, 10]}\n",
    "\n",
    "scores = {'accuracy': make_scorer(accuracy_score), \n",
    "          'f1': make_scorer(f1_score)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d719a43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "gbc = GradientBoostingClassifier()\n",
    "\n",
    "pre_process = ColumnTransformer([\n",
    "    ('num', StandardScaler(), numeric),\n",
    "    ('cat', OneHotEncoder(), categorical)], n_jobs=-1)\n",
    "\n",
    "gbc_grid = GridSearchCV(gbc, param_grid, scoring=scores, refit=False, cv=3, n_jobs=-1)\n",
    "# gbc_grid.get_params().keys() for troubleshooting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c027e3be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gbc_grid.get_params().keys()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "09ed2719",
   "metadata": {},
   "source": [
    "X_prep = pre_process.fit_transform(X_train)\n",
    "gbc_grid.fit(X_prep, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33691201",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_out = pd.DataFrame.from_dict(gbc_grid.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f06825",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_out_loc = \"../data/inference/grid_out.csv\"\n",
    "grid_out.to_csv(grid_out_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97d44e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", None)\n",
    "grid_out.sort_values(['rank_test_f1','rank_test_accuracy'], ascending=[True, True]).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86251ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_out.sort_values(['rank_test_accuracy','rank_test_f1'], ascending=[True, True]).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30dbfbc",
   "metadata": {},
   "source": [
    "Now to take the parameters of the models with best f1 and accuracy for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6548f982",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_param = {\n",
    "    'criterion': 'mse', \n",
    "    'learning_rate': 0.05, \n",
    "    'loss': 'deviance', \n",
    "    'max_depth': 6, \n",
    "    'max_features': 'sqrt', \n",
    "    'n_estimators': 100, \n",
    "    'n_iter_no_change': 5, \n",
    "    'random_state': 42, \n",
    "    'subsample': 1.0, \n",
    "    'validation_fraction': 0.1}\n",
    "\n",
    "f1_param = {\n",
    "    'criterion': 'mse', \n",
    "    'learning_rate': 0.025, \n",
    "    'loss': 'exponential', \n",
    "    'max_depth': 9, \n",
    "    'max_features': \n",
    "    'log2', \n",
    "    'n_estimators': 250, \n",
    "    'n_iter_no_change': 5, \n",
    "    'random_state': 42, \n",
    "    'subsample': 1.0, \n",
    "    'validation_fraction': 0.1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4dd161",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf_acc = GradientBoostingClassifier(**acc_param).fit(X_prep, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41cc381b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_acc = clf_acc.predict(X_prep)\n",
    "print(classification_report(y_train, y_pred_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54411d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_prep = pre_process.transform(X_test)\n",
    "y_test_acc = clf_acc.predict(X_test_prep)\n",
    "print(classification_report(y_test, y_test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691e8d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_f1 = GradientBoostingClassifier(**f1_param).fit(X_prep, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692a9dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_f1 = clf_f1.predict(X_prep)\n",
    "print(classification_report(y_train, y_pred_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1ceac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_f1 = clf_f1.predict(X_test_prep)\n",
    "print(classification_report(y_test, y_test_f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00a0e0c",
   "metadata": {},
   "source": [
    "Both of these models seem consistent with each other - I don't think much of an improvement can be expected on the held out kaggle set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f89bc4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# convert to code and run if running inference on test set for kaggle submission\n",
    "file_acc = \"../data/inference/cv_acc_gb.csv\"\n",
    "file_f1 = \"../data/inference/cv_f1_gb.csv\"\n",
    "\n",
    "test_df = pd.read_csv(\"../data/raw/test.csv\")\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb2ba44",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee88d292",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "na_fill = {'Embarked': 'X', 'Cabin': 'X', 'Ticket': 'X'}\n",
    "test_df.fillna(value=na_fill, inplace=True)\n",
    "test_df['Cabin'] = test_df['Cabin'].map(lambda x: x[0].strip())\n",
    "test_df['Ticket'] = test_df['Ticket'].map(lambda x:str(x).split()[0] if len(str(x).split()) > 1 else 'X')\n",
    "test_df['Fare'] = test_df['Fare'].fillna(test_df['Pclass'].map(fare_map['Fare']))\n",
    "test_df['Age'] = test_df['Age'].fillna(test_df['Sex'].map(age_map['Age']))\n",
    "test_df.rename(columns={'Cabin': 'CabinArea', 'Ticket': 'TicketStub'}, inplace=True)\n",
    "test_features = test_df[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked', 'CabinArea', 'TicketStub']]\n",
    "test_prep = pre_process.transform(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87195351",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_f1 = clf_f1.predict(test_prep)\n",
    "test_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce3b00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['Survived'] = test_f1.tolist()\n",
    "test_submission = test_df[['PassengerId', 'Survived']]\n",
    "test_submission.to_csv(file_f1, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1af52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc = clf_acc.predict(test_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428fc4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['Survived'] = test_acc.tolist()\n",
    "test_submission = test_df[['PassengerId', 'Survived']]\n",
    "test_submission.to_csv(file_acc, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edde4f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['f1'] = test_f1.tolist()\n",
    "test_df['acc'] = test_acc.tolist()\n",
    "test_df.drop(columns='Survived', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529e70b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_df['diff'] = test_df['f1'] == test_df['acc']\n",
    "test_df['diff'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac9ab70",
   "metadata": {},
   "source": [
    "Although they differ in 1638 cases, both f1 and accuracy GBM models score 0.80394 on the leaderboard - perhaps they differ on the 75% held back for evaluation after the challenge ends.\n",
    "\n",
    "In any case, cracking 80% accuracy on the public leaderboard caused a jump of hundreds of places, so it was good to see some positive impact from a good old fashioned grid search"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
