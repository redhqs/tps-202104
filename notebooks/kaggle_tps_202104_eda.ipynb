{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "serious-dallas",
   "metadata": {},
   "source": [
    "### EDA of Apr 2021 kaggle TPS\n",
    "\n",
    "This notebook is used to do initial exploration of the training data, get an understanding of the distribution and completeness of each column and relationship with the target. The aim is to build a broad understanding and make some baseline predictions.\n",
    "\n",
    "Synthanic [Data Dictionary](https://www.kaggle.com/c/tabular-playground-series-apr-2021/data?select=train.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "raised-specialist",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports for EDA\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "personal-algorithm",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports for inference\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "narrow-davis",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/raw/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floating-bacteria",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "metric-range",
   "metadata": {},
   "source": [
    "We can get some idea of what to expect from the first few rows - next to look at the distribution of each more closely, and think about how to handle missing data and how to encode sex, class, port of embarkation etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opposed-hanging",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organic-applicant",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabulous-raising",
   "metadata": {},
   "source": [
    "So with a 43% survival rate, hopefully we can do better than predicting everyone as lost at 57%. Noticing a lot of missing ages, not so many missing fares. \n",
    "\n",
    "For the purposes of this challend I'm assuming the passenger IDs are all ok - on to survival, and lots of plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "checked-martin",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "sns.displot(data=df, x=\"Survived\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bottom-break",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(data=df, x=\"Pclass\", hue=\"Survived\", multiple=\"stack\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "german-vinyl",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['Sex', 'Survived'])['Survived'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "monthly-cigarette",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Sex'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "received-dealing",
   "metadata": {},
   "source": [
    "No missing values here - but note significant differences in outcomes between male and female."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accepted-heater",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(data=df, x=\"Age\", hue=\"Survived\", kind=\"kde\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "special-region",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['Age'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "illegal-importance",
   "metadata": {},
   "source": [
    "3.3% of values for Age are missing - we may be able to impute this from other columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outer-workshop",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(data=df, x=\"SibSp\", hue=\"Survived\", multiple=\"stack\")\n",
    "# SibSp and Parch will be returned to after a baseline established. apologies for an ugly chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bibliographic-region",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(data=df, x=\"Parch\", hue=\"Survived\", multiple=\"stack\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adverse-effect",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['Ticket'].nunique())\n",
    "print(df['Ticket'].isnull().sum())\n",
    "# After baseline established, should be possible to link families using ticket, cabin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nutritional-challenge",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(df['Fare'].isnull().sum())\n",
    "sns.displot(data=df, x=\"Fare\", hue=\"Survived\", kind=\"kde\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secure-pledge",
   "metadata": {},
   "source": [
    "Those paying < 100 did not do so well. Let's take a closer look at passengers who paid more:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ignored-smart",
   "metadata": {},
   "outputs": [],
   "source": [
    "dplot = sns.displot(data=df, x=\"Fare\", hue=\"Survived\", kind=\"kde\")\n",
    "dplot.set(xlim=(100, 800))\n",
    "dplot.set(ylim=(0, 0.001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "driven-switch",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['Cabin'].nunique())\n",
    "print(df['Cabin'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southwest-northeast",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['Embarked', 'Survived'])['Survived'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ranking-greeting",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['Embarked'].isnull().sum()\n",
    "# A few missing here, to investigate after the first iteration is complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rapid-ancient",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here's a quick/dirty remap to plot embarkation port\n",
    "df['Emb'] = df['Embarked'].map({'C': 0, 'Q': 1, 'S': 2})\n",
    "sns.displot(data=df, x=\"Emb\", hue=\"Survived\", multiple=\"stack\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abandoned-batman",
   "metadata": {},
   "source": [
    "There is work to be done to work out the best way to impute missing data around Age, SibSp, Parch, Ticket, Cabin, and Embarked, but first I want to compare a quick mvp to a dummy benchmark to set a baseline. For this the categorical columns will need to be encoded, nulls filled with temporary junk, after breaking out to a train/test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "empty-flooring",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df[['Survived']]\n",
    "features = df[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "south-kingdom",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "maritime-drove",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = ['Pclass', 'Sex', 'Embarked']\n",
    "numeric = ['Age', 'SibSp', 'Parch', 'Fare']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sustainable-greek",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[numeric].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stable-dietary",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train['Age'] = X_train.groupby(['Sex','Pclass'], sort=False)['Age'].apply(lambda x: x.fillna(x.median()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noticed-population",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['Fare'] = X_train.groupby(['Sex','Pclass'], sort=False)['Fare'].apply(lambda x: x.fillna(x.median()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wooden-cameroon",
   "metadata": {},
   "source": [
    "With numerical blanks filled with median values taken from grouping of sex and class, and a train test split specified, numeric columns are scaled and categorical columns are one hot encoded. Initial estimator is logistic regression for a simple binary classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "relevant-aerospace",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = make_column_transformer(\n",
    "    (StandardScaler(), numeric),\n",
    "    (OneHotEncoder(drop='if_binary'), categorical), \n",
    "    remainder='passthrough')\n",
    "\n",
    "model = make_pipeline(\n",
    "    preprocessor,\n",
    "    LogisticRegression())\n",
    "\n",
    "_ = model.fit(X_train, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "floral-catering",
   "metadata": {},
   "source": [
    "To set a baseline for model performance, let's see a classification report if the ship is predicted as going down with no survivors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collect-savings",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_train)\n",
    "y_dummy = np.full(shape=len(y_pred), fill_value=0)\n",
    "print(classification_report(y_train, y_dummy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "innovative-munich",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accredited-progressive",
   "metadata": {},
   "source": [
    "Performance on training data is ok at 76% overall accuracy; better than guessing that no one makes it at least, at 57% accuracy. Compare to the held out test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "explicit-chance",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_test['Age'] = X_test.groupby(['Sex','Pclass'], sort=False)['Age'].apply(lambda x: x.fillna(x.median()))\n",
    "X_test['Fare'] = X_test.groupby(['Sex','Pclass'], sort=False)['Fare'].apply(lambda x: x.fillna(x.median()))\n",
    "y_unseen = model.predict(X_test)\n",
    "print(classification_report(y_test, y_unseen))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "social-eight",
   "metadata": {},
   "source": [
    "To finish with the same steps are carried out on the competition test set and submitted. With more time you could do EDA on the test set to look for drift across each category, but for right now I'm interested in how this model performs without any additional intervention."
   ]
  },
  {
   "cell_type": "raw",
   "id": "renewable-hypothesis",
   "metadata": {},
   "source": [
    "# convert to code and run if running inference on test set for kaggle submission\n",
    "file_out = \"../data/inference/basic_eda_gb.csv\"\n",
    "test_df = pd.read_csv(\"../data/raw/test.csv\")\n",
    "test_df.head()\n",
    "test_features = test_df[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']]\n",
    "test_features['Age'] = test_features['Age'].fillna(X_train['Age'].median())\n",
    "test_features['Fare'] = test_features['Fare'].fillna(X_train['Fare'].median())\n",
    "test_unseen = model_gb.predict(test_features)\n",
    "test_df['Survived'] = test_unseen.tolist()\n",
    "test_submission = test_df[['PassengerId', 'Survived']]\n",
    "test_submission.to_csv(file_out, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "combined-sleep",
   "metadata": {},
   "source": [
    "This initial submission achieved a leaderboard score of 0.77000. \n",
    "\n",
    "Next steps are:\n",
    "- using an ensemble algorithm on the same data as logistic regression above, measure uplift\n",
    "- look at more intelligent ways of filling nulls, making better use of tickets and cabins to see if that affects survival."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sustained-opinion",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "# yes there needs to be a proper CV grid search eventually - submitting this as is to kaggle yielded leaderboard score of 0.78642\n",
    "model_gb = make_pipeline(\n",
    "    preprocessor,\n",
    "    GradientBoostingClassifier())\n",
    "\n",
    "_ = model_gb.fit(X_train, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "behind-attitude",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_gb = model_gb.predict(X_train)\n",
    "print(classification_report(y_train, y_pred_gb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equivalent-hanging",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_unseen_gb = model_gb.predict(X_test)\n",
    "print(classification_report(y_test, y_unseen_gb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sticky-cleaning",
   "metadata": {},
   "source": [
    "The ensemble method achieved a leaderboard score of 0.78642 out of the box."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
